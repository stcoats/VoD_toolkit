{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "private_outputs": true,
      "authorship_tag": "ABX9TyPsSErvup9wHTak+dt/YHkq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stcoats/VoD_toolkit/blob/main/VoD_toolkit_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If using WhisperX, ensure that \"Runtime\", from the dropdown menu, is GPU."
      ],
      "metadata": {
        "id": "h3aJ5Edgl00b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install the necessary repositories. Don't restart if you get the message \"WARNING: The following packages were previously imported in this runtime:\n",
        "  [pydevd_plugins]\". Just click \"Cancel\"."
      ],
      "metadata": {
        "id": "7ElTFZXsb9KA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8Aj3BzFlU7T",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install yt-dlp\n",
        "!pip install webvtt-py==0.4.6\n",
        "!pip install git+https://github.com/m-bain/whisperx.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import HTML\n",
        "import yt_dlp\n",
        "import glob\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n"
      ],
      "metadata": {
        "id": "4gpzN3-ozs5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Use the code below if you are retrieving VoD from YouTube. If you are retrieving VoD from Twitch, go to 3. below."
      ],
      "metadata": {
        "id": "iQOKcgfGcMl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URLS = ['https://www.youtube.com/watch?v=cUUuRK3Rm4k']\n",
        "\n",
        "ydl_opts = {#'format':'ba[ext=m4a]/ba[ext=mp4]',\n",
        "                    #'overwrites' : True,\n",
        "                    #'extract-audio':False,\n",
        "                    #'audio-format':'wav',\n",
        "                    'writesubtitles':True,\n",
        "\n",
        "                    'writeautomaticsub': True, #This will retrieve the YT-generated Automatic Speech Recognition transcript (not manual transcripts/captions)\n",
        "                    'subtitleslangs': ['en','live_chat'],\n",
        "                    'outtmpl': '/content/%(uploader)s/%(upload_date)s--%(id)s--%(title)s.%(ext)s', #Here we are using yt-dl syntax to capture the channel name, upload date, video id, video title, and file extension\n",
        "                    'skip_download':True,\n",
        "                    #'ignoreerrors': True,\n",
        "}\n",
        "    # ℹ️ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "    #'postprocessors': [{  # Extract audio using ffmpeg\n",
        "    #    'key': 'FFmpegExtractAudio',\n",
        "    #    'preferredcodec': 'm4a',\n",
        "    #}]\n",
        "#}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    error_code = ydl.download(URLS)"
      ],
      "metadata": {
        "id": "NrLcynjLztHt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. For Twitch, a patched version of yt-dlp must be installed"
      ],
      "metadata": {
        "id": "AGg5QLutcXl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall yt-dlp -y\n",
        "!git clone https://github.com/mpeter50/yt-dlp\n",
        "%cd yt-dlp\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .\n",
        "!git checkout twitchvod-livechat"
      ],
      "metadata": {
        "id": "CGVjZ147z9CK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This retrieves the audio from a Twitch VoD."
      ],
      "metadata": {
        "id": "5coTJtCzk3Il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yt-dlp -S \"+size,+wa\" --extract-audio 'https://www.twitch.tv/videos/2231052156' -o \"/content/%(uploader)s/%(title)s.f%(format_id)s.%(ext)s\" --extractor-args Twitch:device_id=did;client_integrity=cit1"
      ],
      "metadata": {
        "id": "7nGfyMTRgA8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the Twitch chat transcript, we will use the TwitchDowloaderCLI"
      ],
      "metadata": {
        "id": "kpmLxlcl3fXL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsWSMsbp3YIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/lay295/TwitchDownloader/releases/download/1.55.0/TwitchDownloaderCLI-1.55.0-Linux-x64.zip\n",
        "!unzip TwitchDownloaderCLI-1.55.0-Linux-x64.zip\n",
        "!sudo chmod +x TwitchDownloaderCLI\n",
        "!./TwitchDownloaderCLI chatdownload --id 2231052156 -o /content/out.html"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BXxJ3WuR3X8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def parse_twitch_comments(file_path):\n",
        "    \"\"\"\n",
        "    Parses a Twitch chat log HTML file and returns a DataFrame with embedded images for badges and emotes.\n",
        "\n",
        "    Parameters:\n",
        "        file_path (str): The path to the input HTML file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing 'time', 'author', and 'message'.\n",
        "    \"\"\"\n",
        "    # Read the HTML content from the file\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        html_data = file.read()\n",
        "\n",
        "    # Parse the HTML using BeautifulSoup\n",
        "    soup = BeautifulSoup(html_data, 'html.parser')\n",
        "\n",
        "    # List to hold the parsed data\n",
        "    data = []\n",
        "\n",
        "    # Extract information from each 'pre' element\n",
        "    for comment in soup.find_all('pre', class_='comment-root'):\n",
        "        time = comment.text.split(']')[0].strip('[')  # Extract timestamp\n",
        "\n",
        "        # Find the badge image (if exists)\n",
        "        badge_img_tag = comment.find('img', class_='badge-image')\n",
        "        badge_img = badge_img_tag['src'] if badge_img_tag else None  # Extract image URL\n",
        "\n",
        "        # Extract author name\n",
        "        author = comment.find('span', class_='comment-author').text if comment.find('span', class_='comment-author') else None\n",
        "\n",
        "        # Create author column combining username and badge image\n",
        "        if badge_img:\n",
        "            author = f'{author} <img src=\"{badge_img}\" width=\"20\">'  # Append badge image next to author name\n",
        "\n",
        "        # Extract comment message\n",
        "        message = comment.find('span', class_='comment-message').text.strip(': ') if comment.find('span', class_='comment-message') else \"\"\n",
        "\n",
        "        # Find and append emote images within the message\n",
        "        for emote_img_tag in comment.find_all('img', class_='emote-image'):\n",
        "            emote_img_url = emote_img_tag['src']\n",
        "            emote_img_tag = f'<img src=\"{emote_img_url}\" width=\"20\">'\n",
        "            message += f' {emote_img_tag}'  # Append emote image within the message\n",
        "\n",
        "        # Append the extracted data to the list\n",
        "        data.append([time, author, message])\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data, columns=['time', 'author', 'message'])\n",
        "\n",
        "    # Convert the DataFrame to HTML and display the rendered images\n",
        "    #return HTML(df.to_html(escape=False))\n",
        "    return df\n",
        "# Example usage:\n",
        "twitch_df = parse_twitch_comments(\"/content/out.html\")\n",
        "# display(result)"
      ],
      "metadata": {
        "id": "khfJvtLa3j4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If ASR captions are not available, they can be created with WhisperX"
      ],
      "metadata": {
        "id": "DaKsVa1jYsRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisperx\n",
        "import gc\n",
        "\n",
        "device = \"cuda\"\n",
        "audio_file = glob.glob(\"/content/*/*.m*\")\n",
        "batch_size = 16 # reduce if low on GPU mem\n",
        "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
        "model = whisperx.load_model(\"small\", device, compute_type=compute_type)\n",
        "\n",
        "audio = whisperx.load_audio(audio_file[0])\n",
        "result = model.transcribe(audio, batch_size=batch_size)\n",
        "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
        "result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
        "whisper_df = pd.DataFrame(result[\"segments\"])\n",
        "whisper_df1 = whisper_df[[\"start\",\"text\"]]\n",
        "whisper_df1.columns = [\"time\",\"text\"]"
      ],
      "metadata": {
        "id": "oFIT4_tPYrWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_df1"
      ],
      "metadata": {
        "id": "LlPHOY--4WMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell is for YouTube VoD\n",
        "\n",
        "json_path = glob.glob(\"/content/P*/*.json\")\n",
        "vtt_path =  glob.glob(\"/content/P*/*.en.vtt\")\n",
        "json_data = pd.read_json(json_path[0],\n",
        "                    orient='records',\n",
        "                    lines=True)"
      ],
      "metadata": {
        "id": "ATAh9R_bz8_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vtt_text = open(vtt_path[0], \"r\").read()\n",
        "hits = re.findall(r\"(?<!<)\\d\\d\\:\\d\\d\\:\\d\\d\\.\\d\\d\\d.*\\n.+?\\n.+?\\n\", vtt_text, flags=re.M)\n",
        "raw_text = [(x.split(\"\\n\")[0], re.sub(\"(?:<\\s?\\d\\d\\:\\d\\d\\:\\d\\d\\.\\d\\d\\d>|</?c>)\",\"\",x.split(\"\\n\")[-2])) for x in hits]\n",
        "text1 = [re.sub(\" align:start position:0%\",\"\",y[0]) for y in raw_text if not y[1] == \" \"]\n",
        "text2 = [re.sub(\" align:start position:0%\",\"\",y[1]) for y in raw_text if not y[1] == \" \"]\n",
        "text3 = []\n",
        "for z in zip(text1,text2):\n",
        "    text3.append(z)\n",
        "pd.DataFrame(text3)\n",
        "\n",
        "transcript_df = pd.DataFrame(text3)"
      ],
      "metadata": {
        "id": "X2RkzYD30arJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_content(input_df):\n",
        "  extracted_messages = []\n",
        "  for entry in input_df['replayChatItemAction']:\n",
        "      #entry1 = json.loads(entry)\n",
        "      actions = entry.get(\"actions\", [])\n",
        "      for action in actions:\n",
        "          item = action.get(\"addChatItemAction\", {}).get(\"item\", {})\n",
        "          renderer = item.get(\"liveChatTextMessageRenderer\", {})\n",
        "          message_runs = renderer.get(\"message\", {}).get(\"runs\", [])\n",
        "          author_name = renderer.get(\"authorName\", {}).get(\"simpleText\", \"\")\n",
        "          timestamp_usec = renderer.get(\"timestampText\", {}).get(\"simpleText\", \"\")\n",
        "          badge_url = ''\n",
        "\n",
        "          try:\n",
        "              # Get author badges (if any)\n",
        "              badges = renderer.get(\"authorBadges\", [])\n",
        "\n",
        "              # Loop through the badges and find the 32px thumbnail\n",
        "              for badge in badges:\n",
        "                  badge_thumbnails = badge.get('liveChatAuthorBadgeRenderer', {}).get('customThumbnail', {}).get('thumbnails', [])\n",
        "                  for thumbnail in badge_thumbnails:\n",
        "                      if thumbnail.get('width') == 32:  # Check if it's a 32-pixel image\n",
        "                          badge_url = thumbnail.get('url', 'No badge')\n",
        "                          break\n",
        "          except (KeyError, IndexError):\n",
        "              badge_url = ''\n",
        "          if badge_url != '':\n",
        "            author_name = author_name + ' <img src=' + badge_url + '>'\n",
        "\n",
        "          # Initialize message content\n",
        "          message_content = []\n",
        "          for run in message_runs:\n",
        "              if \"text\" in run:\n",
        "                  message_content.append(run[\"text\"])\n",
        "              elif \"emoji\" in run:\n",
        "                  emoji_info = run[\"emoji\"]\n",
        "                  emoji_label = emoji_info.get(\"image\", {}).get(\"accessibility\", {}).get(\"accessibilityData\", {}).get(\"label\", \"\")\n",
        "                  if len(emoji_info.get(\"image\", {}).get(\"thumbnails\", {})) == 1:\n",
        "                      emoji_image = emoji_info.get(\"image\", {}).get(\"thumbnails\", {})[0].get(\"url\", \"\")\n",
        "                  else:\n",
        "                      emoji_image = emoji_info.get(\"image\", {}).get(\"thumbnails\", {})[1].get(\"url\", \"\")\n",
        "                  if emoji_info.get(\"isCustomEmoji\") == True:\n",
        "                      message_content.append(f'<img src=\"{emoji_image}\">')\n",
        "                  else:\n",
        "                      message_content.append(f\"{emoji_label}\")  # Formatting the emoji with colons\n",
        "\n",
        "          # Join all parts of the message (text and emojis)\n",
        "          full_message = \"\".join(message_content)\n",
        "\n",
        "          # Append the extracted data to the list\n",
        "          extracted_messages.append({\n",
        "              \"timestamp_usec\": timestamp_usec,\n",
        "              \"author\": author_name,\n",
        "              \"message\": full_message\n",
        "          })\n",
        "  return extracted_messages\n"
      ],
      "metadata": {
        "id": "ouzciPxC1TDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_df = pd.DataFrame(extract_content(json_data))\n",
        "chat_df"
      ],
      "metadata": {
        "id": "Yhj6o7hR1TJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_df"
      ],
      "metadata": {
        "id": "9jn4isVP2LLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_df.columns = [\"time\",\"author\",\"message\"]\n",
        "transcript_df.columns = [\"time\",\"text\"]\n",
        "transcript_df[\"time\"] = [x.split(\" --> \")[0] for x in transcript_df.time]"
      ],
      "metadata": {
        "id": "mISUtBrn2LOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def string_to_timedelta(time_str):\n",
        "    if not pd.isnull(time_str):\n",
        "        # Split the time string into hours, minutes, and seconds\n",
        "        if time_str.startswith(\"-\"):\n",
        "            time_str = time_str.replace(\"-\",\"\")\n",
        "            parts = time_str.split(':')\n",
        "            if len(parts) == 3:\n",
        "                hours = int(parts[0])\n",
        "                minutes = int(parts[1])\n",
        "                seconds = float(parts[2])\n",
        "            elif len(parts) == 2:\n",
        "                hours = 0\n",
        "                minutes = int(parts[0])\n",
        "                seconds = float(parts[1])\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "            # Convert hours, minutes, and seconds to timedelta\n",
        "            time_delta = -timedelta(hours=hours, minutes=minutes, seconds=seconds).total_seconds()\n",
        "        else:\n",
        "            parts = time_str.split(':')\n",
        "            if len(parts) == 3:\n",
        "                hours = int(parts[0])\n",
        "                minutes = int(parts[1])\n",
        "                seconds = float(parts[2])\n",
        "            elif len(parts) == 2:\n",
        "                hours = 0\n",
        "                minutes = int(parts[0])\n",
        "                seconds = float(parts[1])\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "            # Convert hours, minutes, and seconds to timedelta\n",
        "            time_delta = timedelta(hours=hours, minutes=minutes, seconds=seconds).total_seconds()\n",
        "\n",
        "        return time_delta"
      ],
      "metadata": {
        "id": "TpzzkkZY2XGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2ID-IKWz2sj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge the chat and transcript data for YouTube VoDs"
      ],
      "metadata": {
        "id": "DQ1cKVRhPntA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_df[\"time\"] = chat_df[\"time\"].apply(lambda x: string_to_timedelta(x))\n",
        "transcript_df[\"time\"] = transcript_df[\"time\"].apply(lambda x: string_to_timedelta(x))\n",
        "merged_df = pd.merge_ordered(transcript_df, chat_df, on='time')\n",
        "#If you have the WhisperX ASR transcript, rather than the one provided by YouTube, comment out the line above and use the line below\n",
        "#merged_df = pd.merge_ordered(whisper_df1, chat_df, on='time')\n"
      ],
      "metadata": {
        "id": "0TntrmBZ2XLw",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge the chat and transcript data for Twitch VoDs"
      ],
      "metadata": {
        "id": "XyR--SdUPvjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitch_df[\"time\"] = twitch_df[\"time\"].apply(lambda x: string_to_timedelta(x))\n",
        "merged_df = pd.merge_ordered(whisper_df1, twitch_df, on='time')\n",
        "merged_df = merged_df[merged_df[\"time\"].notnull()].sort_values(by=\"time\")"
      ],
      "metadata": {
        "id": "Ezd0NB2-PjBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame to HTML\n",
        "merged_df1 = merged_df.fillna(\"\")\n",
        "merged_df1.to_html(\"/content/output.html\", index=False, render_links=True, escape=False)\n",
        "\n",
        "# HTML Content to add (Bootstrap + Custom Styles + JavaScript for sortable table)\n",
        "html_content = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "<title>Document</title>\n",
        "<link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css\">\n",
        "<style>\n",
        "  .table-wrapper {\n",
        "    overflow: auto;\n",
        "    margin: 0 40px;\n",
        "  }\n",
        "  table {\n",
        "    width: 100% !important;\n",
        "  }\n",
        "</style>\n",
        "<script src=\"https://code.jquery.com/jquery-3.5.1.slim.min.js\"></script>\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/sticky-table-headers/js/jquery.stickytableheaders.min.js\"></script>\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"table-wrapper\">\n",
        "<table border=\"1\" class=\"dataframe table table-striped\">\n",
        "  <thead class=\"thead-dark\">\n",
        "    <tr style=\"text-align: left;\">\n",
        "\"\"\"\n",
        "\n",
        "# Read the original HTML file\n",
        "with open(\"/content/output.html\", \"r\") as file:\n",
        "    original_html = file.read()\n",
        "\n",
        "\n",
        "# Replace the first part of the HTML with our header and add the original table\n",
        "updated_html = html_content + original_html.replace('<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">',\n",
        "                     '<table border=\"1\" class=\"dataframe table table-striped\">\\n <thead class=\"thead-dark\">\\n <tr style=\"text-align: left;\">') + \"\"\"\n",
        "</div>\n",
        "<script>\n",
        "  $(document).ready(function() {\n",
        "    $(\"table\").stickyTableHeaders();\n",
        "  });\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Write the modified HTML back to the file\n",
        "with open(\"/content/output.html\", \"w\") as file:\n",
        "    file.write(updated_html)"
      ],
      "metadata": {
        "id": "sinYvgJd2XQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mer2 = merged_df.groupby(['time'])\\\n",
        "    .agg(chat=('message','count'),\n",
        "         speech=('text','count')).reset_index()\n",
        "\n",
        "mer2['time'] = (mer2['time'] / 60).astype(int)\n",
        "\n",
        "# Group by the new time column and sum the other columns\n",
        "result_df = mer2.groupby('time').sum().reset_index()\n",
        "result_df2 = pd.melt(result_df, id_vars='time', value_vars=['chat', 'speech'])\n",
        "result_df2.columns = [\"time\", \"mode\",\"value\"]"
      ],
      "metadata": {
        "id": "Cz_J2IQs2XWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DuGlTbso3Zeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"darkgrid\")\n",
        "sns.set_context(\"talk\")\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.lineplot(data=result_df2, x='time', y='value', hue='mode')\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
        "ax.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
        "plt.xlabel('Time in minutes')\n",
        "plt.ylabel('Message Density')\n",
        "plt.title('Message Density Over Time')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"message_density.png\",dpi=600)\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XuxTuApL3Zha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nRTw0bYJ3Zju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5BHejBkI3ZmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZDip_2P83ZoZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}